package fabric.metrics;

import java.util.Arrays;
import fabric.util.LinkedHashMap;
import fabric.util.Map;
import java.util.Iterator;

import fabric.common.ConfigProperties;
import fabric.metrics.contracts.Bound;
import fabric.metrics.util.Observer;
import fabric.metrics.util.Subject;

import fabric.worker.Store;
import fabric.worker.transaction.TransactionManager;

import fabric.worker.metrics.SumStrategy;
import fabric.worker.metrics.StatsMap;
import fabric.worker.metrics.treaties.enforcement.DirectPolicy;
import fabric.worker.metrics.treaties.enforcement.EnforcementPolicy;
import fabric.worker.metrics.treaties.enforcement.WitnessPolicy;
import fabric.worker.metrics.treaties.statements.EqualityStatement;
import fabric.worker.metrics.treaties.statements.TreatyStatement;
import fabric.worker.metrics.treaties.statements.ThresholdStatement;

import com.google.common.collect.Multimap;
import com.google.common.collect.HashMultimap;

import java.util.logging.Level;
import fabric.common.Logging;

/**
 * A {@link DerivedMetric} for the sum of the given metric terms.
 */
public class SumMetric extends DerivedMetric {

    /**
     * @param store
     *            the {@link Store} that holds this {@link Metric}
     * @param terms
     *            The {@link Metric}s this applies to
     */
    public SumMetric fabric$metrics$SumMetric$(Metric native[] terms) {
        fabric$metrics$DerivedMetric$(terms);
        initialize();
        return this;
    }

    /*@Override*/
    public double computePresetR() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetR();
        }
        return result;
    }

    /*@Override*/
    public double computePresetB() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetB();
        }
        return result;
    }

    /*@Override*/
    public double computePresetV() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetV();
        }
        return result;
    }

    /*@Override*/
    public double computePresetN() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetN();
        }
        return result;
    }

    /*@Override*/
    protected double computeValue(StatsMap weakStats) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
          result += term(i).value(weakStats);
        }
        return result;
    }

    /*@Override*/
    protected double computeVelocity(StatsMap weakStats) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
          result += term(i).velocity(weakStats);
        }
        return result;
    }

    /*@Override*/
    protected double computeNoise(StatsMap weakStats) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
          result += term(i).noise(weakStats);
        }
        return result;
    }

    /*@Override*/
    public String toString() {
        String str = "(";
        boolean nonEmpty = false;
        for (int i = 0; i < terms.length(); i++) {
            if (nonEmpty)
                str += " + ";
            nonEmpty = true;
            str += term(i);
        }
        return str + ")@" + getStore();
    }

    /*@Override*/
    // Pushing down really messes with tree structure when sharing weak
    // estimation across subexpressions but not doing so causes handling
    // negation of multistore treaties to loop.  For now we push down. In the
    // future, we should improve handling of negated metrics to get the best of
    // both worlds.
    //
    // Note: The current design means that refreshLocally on a metric times(x)
    // is *not* enough to update weak estimates.
    public DerivedMetric times(double scalar) {
      //Double s = Double.valueOf(scalar);
      //DerivedMetric result = (DerivedMetric) getTimesCache().get(s);
      //if (result == null) {
      //  result = static_times(this, scalar);
      //  if (TransactionManager.getInstance().inTxn()) {
      //    getTimesCache().put(s, result);
      //  } else {
      //    atomic {
      //      getTimesCache().put(s, result);
      //    }
      //  }
      //}
      //return result;
      return static_times(this, scalar);
    }

    private static DerivedMetric static_times(SumMetric tmp, double scalar) {
        Metric native[] newTerms = new Metric native[tmp.terms.length()];
        for (int i = 0; i < tmp.terms.length(); i++)
          newTerms[i] = tmp.term(i).times(scalar);
        final Store s = tmp.$getStore();
        DerivedMetric val = null;
        if (TransactionManager.getInstance().inTxn()) {
          val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
        } else {
          atomic {
            val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
          }
        }
        return val;
    }

    /**
     * {@inheritDoc}
     * <p>
     * {@link SumMetric}s try to consolidate local computations so that there
     * isn't unnecessary nodes in the {@link Subject}-{@link Observer} tree for
     * {@link #handleUpdates()}.
     */
    // TODO: Combine shared terms with different coefficients.
    public DerivedMetric plus(Metric other) {
      //DerivedMetric result = (DerivedMetric) getPlusCache().get(other);
      //if (result == null) {
      //  result = static_plus(this, other);
      //  if (TransactionManager.getInstance().inTxn()) {
      //    getPlusCache().put(other, result);
      //    other.getPlusCache().put(this, result);
      //  } else {
      //    atomic {
      //      getPlusCache().put(other, result);
      //      other.getPlusCache().put(this, result);
      //    }
      //  }
      //}
      //return result;
      return static_plus(this, other);
    }

    private static DerivedMetric static_plus(SumMetric tmp, Metric other) {
        final Store s = tmp.$getStore();
        // Add in all of the terms of another sum, one by one
        if (other instanceof SumMetric && other.$getStore().equals(s)) {
            SumMetric that = (SumMetric) other;

            DerivedMetric result = tmp;
            for (int i = 0; i < that.terms.length(); i++) {
                result = result.plus(that.term(i));
            }
            return result;
        }

        // If the leaves of the new term are all present in an existing term
        // computed on this store, add them together as a single term instead of
        // adding a new term. (This helps group together ScaledMetrics with the
        // same base term).
        int termIdx = -1;
        if (other instanceof DerivedMetric) {
            DerivedMetric derivedOther = (DerivedMetric) other;
            for (int i = 0; i < tmp.terms.length(); i++) {
                if (!tmp.term(i).$getStore().equals(other.$getStore()))
                    continue;
                if (tmp.term(i) instanceof DerivedMetric) {
                    DerivedMetric derivedTerm = (DerivedMetric) tmp.term(i);
                    if (Arrays.asList(derivedTerm.getLeafSubjects().array())
                            .containsAll(Arrays.asList(derivedOther.getLeafSubjects().array()))) {
                        termIdx = i;
                        break;
                    }
                } else {
                    SampledMetric sampledTerm = (SampledMetric) tmp.term(i);
                    if (derivedOther.getLeafSubjects().length() == 1
                            && Arrays.asList(derivedOther.getLeafSubjects().array())
                                    .contains(sampledTerm)) {
                        termIdx = i;
                        break;
                    }
                }
            }
        } else {
            SampledMetric sampledOther = (SampledMetric) other;
            for (int i = 0; i < tmp.terms.length(); i++) {
                if (!tmp.term(i).$getStore().equals(other.$getStore()))
                    continue;
                if (tmp.term(i) instanceof DerivedMetric) {
                    DerivedMetric derivedTerm = (DerivedMetric) tmp.term(i);
                    if (Arrays.asList(derivedTerm.getLeafSubjects().array()).contains(sampledOther)) {
                        termIdx = i;
                        break;
                    }
                } else {
                    SampledMetric sampledTerm = (SampledMetric) tmp.term(i);
                    if (sampledTerm.equals(sampledOther)) {
                        termIdx = i;
                        break;
                    }
                }
            }
        }

        Metric native[] newTerms = null;
        if (termIdx >= 0) {
            newTerms = new Metric native[tmp.terms.length()];
            for (int i = 0; i < tmp.terms.length(); i++)
              newTerms[i] = tmp.term(i);
            newTerms[termIdx] = newTerms[termIdx].plus(other);
        } else {
            newTerms = new Metric native[tmp.terms.length() + 1];
            for (int i = 0; i < tmp.terms.length(); i++)
              newTerms[i] = tmp.term(i);
            newTerms[tmp.terms.length()] = other;
            Arrays.sort(newTerms, 0, newTerms.length);
        }
        DerivedMetric val = null;
        if (TransactionManager.getInstance().inTxn()) {
          val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
        } else {
          atomic {
            val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
          }
        }
        return val;
    }

    //public static final long MIN_ADAPTIVE_EXPIRY = 60000;

    /*@Override*/
    public EnforcementPolicy thresholdPolicy(double rate, double base, StatsMap weakStats, final Store s) {
      // Don't do this if we want to avoid conflicts between local concurrent
      // operations on different metrics in a derived metric...
      //if (isSingleStore())
      //    return DirectPolicy.singleton;

      long currentTime = System.currentTimeMillis();
      double baseNow = Bound.value(rate, base, currentTime);

      // Defend all rows against the bound individually, using the strictest
      // bounds across the rows for each term in this sum.
      double totalSamples = samples(weakStats);
      double totalValue = value(weakStats);
      double totalVelocity = velocity(weakStats);
      double totalNoise = noise(weakStats);
      int numTerms = terms.length();
      ConfigProperties config = Worker.getWorker().config;

      if (config.usePresetStrategy) {

        Multimap/*<Metric, TreatyStatement>*/ witnesses = HashMultimap/*<>*/.create();

        // For each term, update the associated bounds to be the tightest
        // bound set across the rows
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          double scaledX = m.value(weakStats);

          //// Adaptive version
          // Corrected for the way this metric is shifting relative to
          // the rest of the sum
          double r = m.getPresetR();

          // TODO: Change to account for update frequency in addition to
          // noise, we don't need to be aggressive if a high noise value is
          // updated much less frequently than the other values in the sum.
          double b = scaledX - ((m.getPresetB() / getPresetB()) * (totalValue - baseNow));

          TreatyStatement newStmt = ThresholdStatement.create(r, b, currentTime);
          boolean implied = false;
          for (Iterator/*<TreatyStatement>*/ iter = witnesses.get(m).iterator(); iter.hasNext();) {
            TreatyStatement stmt = (TreatyStatement) iter.next();
            if (stmt.implies(newStmt)) {
              implied = true;
              break;
            }
          }
          if (!implied) {
            witnesses.put(m, newStmt);
          }
        }

        return WitnessPolicy.create(witnesses);
      } else {
        // TODO: Make the samples cutoff configurable.
        //double baseFactor = totalSamples > 10 ? 0.0 / Math.sqrt(totalSamples) : 1.0;
        //double baseFactor = totalSamples > 1 ? 1.0 / totalSamples : 1.0;
        double baseFactor = 0.0;
        double newFactor = 1.0 - baseFactor;

        double native [] velocities = new double native [numTerms];
        double native [] adaptiveRates = new double native [numTerms];
        double native [] staticRates = new double native [numTerms];
        double native [] noises = new double native [numTerms];
        boolean hasSlackProducer = false;
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          velocities[j] = m.velocity(weakStats);
          hasSlackProducer = hasSlackProducer || velocities[j] > rate;
          noises[j] = m.noise(weakStats);

          //// Adaptive version
          // Corrected for the way this metric is shifting relative to
          // the rest of the sum
          adaptiveRates[j] = (newFactor * (velocities[j] - (totalVelocity / numTerms))) + (rate / numTerms);
          staticRates[j] = (rate / numTerms);
        }

        if (Logging.METRICS_LOGGER.isLoggable(Level.FINE)) {
          Logging.METRICS_LOGGER.log(Level.FINE,
              "Running strategy for {0} with velocities {1} and noises {2}",
              new java.lang.Object native[] {
                this,
                Arrays.toString(velocities),
                Arrays.toString(noises)
              });
        }

        // No matter what, get the static strategy.
        double native [] staticSlacks = SumStrategy.getSplit(velocities, noises, staticRates, (totalValue - baseNow));
        // For each term, update the associated bounds to be the tightest
        // bound set across the rows
        Multimap/*<Metric, TreatyStatement>*/ staticWitnesses = HashMultimap/*<>*/.create();
        long staticTimeout = Long.MAX_VALUE;
        long staticRealTimeout = Long.MAX_VALUE;
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          double scaledX = m.value(weakStats);

          //// Static version
          double r = staticRates[j];

          // TODO: Change to account for update frequency in addition to
          // noise, we don't need to be aggressive if a high noise value is
          // updated much less frequently than the other values in the sum.
          double b = scaledX - staticSlacks[j];

          ThresholdStatement newStmt = ThresholdStatement.create(r, b, currentTime);
          boolean implied = false;
          for (Iterator/*<TreatyStatement>*/ iter = staticWitnesses.get(m).iterator(); iter.hasNext();) {
            TreatyStatement stmt = (TreatyStatement) iter.next();
            if (stmt.implies(newStmt)) {
              implied = true;
              break;
            }
          }
          if (!implied) {
            staticWitnesses.put(m, newStmt);
            // Update the timeout estimate.
            staticTimeout = Math.min(staticTimeout, ThresholdStatement.hedgedEstimate(m, newStmt.rate(), newStmt.base(), currentTime, weakStats));
            staticRealTimeout = Math.min(staticRealTimeout, ThresholdStatement.hedgedExpiry(m, newStmt.rate(), newStmt.base(), currentTime, weakStats));
          }
        }

        // Size should be the same for either option.
        Multimap/*<Metric, TreatyStatement>*/ finalWitnesses = staticWitnesses;

        // It's only worth using an adaptive strategy if we have a term that
        // will generate slack and either this is multi-store (and therefore
        // should avoid coordination at all costs) or is already required to run
        // extensions (rate > 0).
        if (config.useDynamic && hasSlackProducer && (!isSingleStore() || rate > 0)) {
          // If there's a slack producer, see if the dynamic strategy is better.
          double native [] adaptiveSlacks = SumStrategy.getSplitEqualVelocity(velocities, noises, adaptiveRates, (totalValue - baseNow));

          Multimap/*<Metric, TreatyStatement>*/ adaptiveWitnesses = HashMultimap/*<>*/.create();
          long adaptiveTimeout = Long.MAX_VALUE;
          long adaptiveRealTimeout = Long.MAX_VALUE;
          for (int j = 0; j < numTerms; j++) {
            Metric m = term(j);
            double scaledX = m.value(weakStats);

            //// Adaptive version
            // Corrected for the way this metric is shifting relative to
            // the rest of the sum
            double r = adaptiveRates[j];

            // TODO: Change to account for update frequency in addition to
            // noise, we don't need to be aggressive if a high noise value is
            // updated much less frequently than the other values in the sum.
            double b = scaledX - adaptiveSlacks[j];

            ThresholdStatement newStmt = ThresholdStatement.create(r, b, currentTime);
            boolean implied = false;
            for (Iterator/*<TreatyStatement>*/ iter = adaptiveWitnesses.get(m).iterator(); iter.hasNext();) {
              TreatyStatement stmt = (TreatyStatement) iter.next();
              if (stmt.implies(newStmt)) {
                implied = true;
                break;
              }
            }
            if (!implied) {
              adaptiveWitnesses.put(m, newStmt);
              // Update the timeout estimate.
              adaptiveTimeout = Math.min(adaptiveTimeout, ThresholdStatement.hedgedEstimate(m, newStmt.rate(), newStmt.base(), currentTime, weakStats));
              adaptiveRealTimeout = Math.min(adaptiveRealTimeout, ThresholdStatement.hedgedExpiry(m, newStmt.rate(), newStmt.base(), currentTime, weakStats));
            }
          }

          // TODO: there should be some dynamic growth of MIN_ADAPTIVE_EXPIRY to
          // account for absurdly long transaction times.
          //if (adaptiveTimeout > staticTimeout && adaptiveRealTimeout >= System.currentTimeMillis() + MIN_ADAPTIVE_EXPIRY) {
          //if (adaptiveTimeout > staticTimeout [>&& adaptiveRealTimeout >= System.currentTimeMillis() + TransactionManager.getInstance().getCurrentTreatyTimeout()<]) {
          if (adaptiveTimeout > staticTimeout && adaptiveRealTimeout > updateInterval(weakStats)/*&& adaptiveRealTimeout >= System.currentTimeMillis() + TransactionManager.getInstance().getCurrentTreatyTimeout()*/) {
            if (adaptiveTimeout != Long.MAX_VALUE)
              Logging.METRICS_LOGGER.log(Level.FINE,
                  "Using adaptive strategy for {0} with adaptive {1} vs static {2} and expected adaptive {3} vs expected static {4}",
                  new java.lang.Object native[] {
                    this,
                    Long.valueOf(adaptiveTimeout),
                    Long.valueOf(staticTimeout),
                    Long.valueOf(adaptiveRealTimeout),
                    Long.valueOf(staticRealTimeout),
                  });
            finalWitnesses = adaptiveWitnesses;
          } else {
              Logging.METRICS_LOGGER.log(Level.FINE,
                  "Using nonadaptive strategy for {0} with adaptive {1} vs static {2} and expected adaptive {3} vs expected static {4}",
                  new java.lang.Object native[] {
                    this,
                    Long.valueOf(adaptiveTimeout),
                    Long.valueOf(staticTimeout),
                    Long.valueOf(adaptiveRealTimeout),
                    Long.valueOf(staticRealTimeout),
                  });
          }
        }

        return WitnessPolicy.create(finalWitnesses);
      }
    }

    /*@Override*/
    public int hashCode() {
        return Arrays.hashCode(terms.array()) * 32 + getStore().hashCode();
    }

    /*@Override*/
    public boolean equals(Object other) {
        if (other instanceof SumMetric) {
            SumMetric that = (SumMetric) other;
            return Arrays.deepEquals(this.terms.array(), that.terms.array())
                    && this.$getStore().equals(that.$getStore());
        }
        return false;
    }
}

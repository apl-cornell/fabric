package fabric.metrics;

import java.util.Arrays;
import fabric.util.LinkedHashMap;
import fabric.util.Map;
import fabric.util.Iterator;

import fabric.common.ConfigProperties;
import fabric.metrics.contracts.Bound;
import fabric.metrics.contracts.Contract;
import fabric.metrics.contracts.enforcement.DirectPolicy;
import fabric.metrics.contracts.enforcement.EnforcementPolicy;
import fabric.metrics.contracts.enforcement.WitnessPolicy;
import fabric.metrics.util.Observer;
import fabric.metrics.util.Subject;

import fabric.worker.Store;
import fabric.worker.transaction.TransactionManager;

import fabric.worker.metrics.SumStrategy;

import java.util.logging.Level;
import fabric.common.Logging;

/**
 * A {@link DerivedMetric} for the sum of the given metric terms.
 */
public class SumMetric extends DerivedMetric {

    /**
     * @param store
     *            the {@link Store} that holds this {@link Metric}
     * @param terms
     *            The {@link Metric}s this applies to
     */
    public SumMetric fabric$metrics$SumMetric$(Metric native[] terms) {
        fabric$metrics$DerivedMetric$(terms);
        initialize();
        return this;
    }

    /*@Override*/
    public double computePresetR() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetR();
        }
        return result;
    }

    /*@Override*/
    public double computePresetB() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetB();
        }
        return result;
    }

    /*@Override*/
    public double computePresetV() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetV();
        }
        return result;
    }

    /*@Override*/
    public double computePresetN() {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).getPresetN();
        }
        return result;
    }

    /*@Override*/
    protected double computeValue(boolean useWeakCache) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).value(useWeakCache);
        }
        return result;
    }

    /*@Override*/
    protected double computeVelocity(boolean useWeakCache) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).velocity(useWeakCache);
        }
        return result;
    }

    /*@Override*/
    protected double computeNoise(boolean useWeakCache) {
        double result = 0;
        for (int i = 0; i < terms.length(); i++) {
            result += term(i).noise(useWeakCache);
        }
        return result;
    }

    /*@Override*/
    public String toString() {
        String str = "(";
        boolean nonEmpty = false;
        for (int i = 0; i < terms.length(); i++) {
            if (nonEmpty)
                str += " + ";
            nonEmpty = true;
            str += term(i);
        }
        return str + ")@" + getStore();
    }

    /*@Override*/
    // Pushing down really messes with tree structure when sharing weak
    // estimation across subexpressions but not doing so causes handling
    // negation of multistore contracts to loop.  For now we push down. In the
    // future, we should improve handling of negated metrics to get the best of
    // both worlds.
    //
    // Note: The current design means that refreshLocally on a metric times(x)
    // is *not* enough to update weak estimates.
    public DerivedMetric times(double scalar) {
      //Double s = Double.valueOf(scalar);
      //DerivedMetric result = (DerivedMetric) getTimesCache().get(s);
      //if (result == null) {
      //  result = static_times(this, scalar);
      //  if (TransactionManager.getInstance().inTxn()) {
      //    getTimesCache().put(s, result);
      //  } else {
      //    atomic {
      //      getTimesCache().put(s, result);
      //    }
      //  }
      //}
      //return result;
      return static_times(this, scalar);
    }

    private static DerivedMetric static_times(SumMetric tmp, double scalar) {
        Metric native[] newTerms = new Metric native[tmp.terms.length()];
        for (int i = 0; i < tmp.terms.length(); i++)
          newTerms[i] = tmp.term(i).times(scalar);
        final Store s = tmp.$getStore();
        DerivedMetric val = null;
        if (TransactionManager.getInstance().inTxn()) {
          val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
        } else {
          atomic {
            val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
          }
        }
        return Metric.findDerivedMetric(s, val);
    }

    /**
     * {@inheritDoc}
     * <p>
     * {@link SumMetric}s try to consolidate local computations so that there
     * isn't unnecessary nodes in the {@link Subject}-{@link Observer} tree for
     * {@link #handleUpdates()}.
     */
    // TODO: Combine shared terms with different coefficients.
    public DerivedMetric plus(Metric other) {
      //DerivedMetric result = (DerivedMetric) getPlusCache().get(other);
      //if (result == null) {
      //  result = static_plus(this, other);
      //  if (TransactionManager.getInstance().inTxn()) {
      //    getPlusCache().put(other, result);
      //    other.getPlusCache().put(this, result);
      //  } else {
      //    atomic {
      //      getPlusCache().put(other, result);
      //      other.getPlusCache().put(this, result);
      //    }
      //  }
      //}
      //return result;
      return static_plus(this, other);
    }

    private static DerivedMetric static_plus(SumMetric tmp, Metric other) {
        final Store s = tmp.$getStore();
        // Add in all of the terms of another sum, one by one
        if (other instanceof SumMetric && other.$getStore().equals(s)) {
            SumMetric that = (SumMetric) other;

            DerivedMetric result = tmp;
            for (int i = 0; i < that.terms.length(); i++) {
                result = result.plus(that.term(i));
            }
            return result;
        }

        // If the leaves of the new term are all present in an existing term
        // computed on this store, add them together as a single term instead of
        // adding a new term. (This helps group together ScaledMetrics with the
        // same base term).
        int termIdx = -1;
        if (other instanceof DerivedMetric) {
            DerivedMetric derivedOther = (DerivedMetric) other;
            for (int i = 0; i < tmp.terms.length(); i++) {
                if (!tmp.term(i).$getStore().equals(other.$getStore()))
                    continue;
                if (tmp.term(i) instanceof DerivedMetric) {
                    DerivedMetric derivedTerm = (DerivedMetric) tmp.term(i);
                    if (Arrays.asList(derivedTerm.getLeafSubjects().array())
                            .containsAll(Arrays.asList(derivedOther.getLeafSubjects().array()))) {
                        termIdx = i;
                        break;
                    }
                } else {
                    SampledMetric sampledTerm = (SampledMetric) tmp.term(i);
                    if (derivedOther.getLeafSubjects().length() == 1
                            && Arrays.asList(derivedOther.getLeafSubjects().array())
                                    .contains(sampledTerm)) {
                        termIdx = i;
                        break;
                    }
                }
            }
        } else {
            SampledMetric sampledOther = (SampledMetric) other;
            for (int i = 0; i < tmp.terms.length(); i++) {
                if (!tmp.term(i).$getStore().equals(other.$getStore()))
                    continue;
                if (tmp.term(i) instanceof DerivedMetric) {
                    DerivedMetric derivedTerm = (DerivedMetric) tmp.term(i);
                    if (Arrays.asList(derivedTerm.getLeafSubjects().array()).contains(sampledOther)) {
                        termIdx = i;
                        break;
                    }
                } else {
                    SampledMetric sampledTerm = (SampledMetric) tmp.term(i);
                    if (sampledTerm.equals(sampledOther)) {
                        termIdx = i;
                        break;
                    }
                }
            }
        }

        Metric native[] newTerms = null;
        if (termIdx >= 0) {
            newTerms = new Metric native[tmp.terms.length()];
            for (int i = 0; i < tmp.terms.length(); i++)
              newTerms[i] = tmp.term(i);
            newTerms[termIdx] = newTerms[termIdx].plus(other);
        } else {
            newTerms = new Metric native[tmp.terms.length() + 1];
            for (int i = 0; i < tmp.terms.length(); i++)
              newTerms[i] = tmp.term(i);
            newTerms[tmp.terms.length()] = other;
            Arrays.sort(newTerms, 0, newTerms.length);
        }
        DerivedMetric val = null;
        if (TransactionManager.getInstance().inTxn()) {
          val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
        } else {
          atomic {
            val = new SumMetric@s().fabric$metrics$SumMetric$(newTerms);
          }
        }
        return Metric.findDerivedMetric(s, val);
    }

    public static final long MIN_ADAPTIVE_EXPIRY = 1000;

    /*@Override*/
    public EnforcementPolicy thresholdPolicy(double rate, double base, boolean useWeakCache, final Store s) {
      // Don't do this if we want to avoid conflicts between local concurrent
      // operations on different metrics in a derived metric...
      //if (isSingleStore())
      //    return new DirectPolicy().fabric$metrics$contracts$enforcement$DirectPolicy$(this, bound);

      long currentTime = System.currentTimeMillis();
      double baseNow = Bound.value(rate, base, currentTime);

      // Defend all rows against the bound individually, using the strictest
      // bounds across the rows for each term in this sum.
      double totalSamples = samples(useWeakCache);
      double totalValue = value(useWeakCache);
      double totalVelocity = velocity(useWeakCache);
      double totalNoise = noise(useWeakCache);
      int numTerms = terms.length();
      ConfigProperties config = Worker.getWorker().config;

      if (config.usePreset) {

        java.util.Map/*<Metric, Contract>*/ witnesses = new java.util.HashMap/*<>*/();

        // For each term, update the associated bounds to be the tightest
        // bound set across the rows
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          double scaledX = m.value(useWeakCache);

          //// Adaptive version
          // Corrected for the way this metric is shifting relative to
          // the rest of the sum
          double r = m.getPresetR();

          // TODO: Change to account for update frequency in addition to
          // noise, we don't need to be aggressive if a high noise value is
          // updated much less frequently than the other values in the sum.
          double b = scaledX - ((m.getPresetB() / getPresetB()) * (totalValue - baseNow));

          double native[] normalized = Bound.createBound(r, b, currentTime);
          if (!witnesses.containsKey(m) || !((Contract) witnesses.get(m)).implies(m, normalized[0], normalized[1])) {
            witnesses.put(m, m.getThresholdContract(r, b, currentTime));
          }
        }

        Contract native[] finalWitnesses = new Contract native[witnesses.size()];
        int i = 0;
        for (java.util.Iterator iter = witnesses.values().iterator(); iter.hasNext();) {
          finalWitnesses[i++] = (Contract) iter.next();
        }

        return new WitnessPolicy@s().fabric$metrics$contracts$enforcement$WitnessPolicy$(finalWitnesses);
      } else {
        // TODO: Make the samples cutoff configurable.
        //double baseFactor = totalSamples > 10 ? 0.0 / Math.sqrt(totalSamples) : 1.0;
        //double baseFactor = totalSamples > 1 ? 1.0 / totalSamples : 1.0;
        double baseFactor = 0.0;
        double newFactor = 1.0 - baseFactor;

        double native [] velocities = new double native [numTerms];
        double native [] adaptiveRates = new double native [numTerms];
        double native [] staticRates = new double native [numTerms];
        double native [] noises = new double native [numTerms];
        boolean hasSlackProducer = false;
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          velocities[j] = m.velocity(useWeakCache);
          hasSlackProducer = hasSlackProducer || velocities[j] > rate;
          noises[j] = m.noise(useWeakCache);

          //// Adaptive version
          // Corrected for the way this metric is shifting relative to
          // the rest of the sum
          adaptiveRates[j] = (newFactor * (velocities[j] - (totalVelocity / numTerms))) + (rate / numTerms);
          staticRates[j] = (rate / numTerms);
        }

        if (Logging.METRICS_LOGGER.isLoggable(Level.FINE)) {
          Logging.METRICS_LOGGER.log(Level.FINE,
              "Running strategy for {0} with velocities {1} and noises {2}",
              new java.lang.Object native[] {
                this,
                Arrays.toString(velocities),
                Arrays.toString(noises)
              });
        }

        // No matter what, get the static strategy.
        double native [] staticSlacks = SumStrategy.getSplit(velocities, noises, staticRates, (totalValue - baseNow));
        // For each term, update the associated bounds to be the tightest
        // bound set across the rows
        java.util.Map/*<Metric, Contract>*/ staticWitnesses = new java.util.HashMap/*<>*/();
        long staticTimeout = Long.MAX_VALUE;
        for (int j = 0; j < numTerms; j++) {
          Metric m = term(j);
          double scaledX = m.value(useWeakCache);

          //// Static version
          double r = staticRates[j];

          // TODO: Change to account for update frequency in addition to
          // noise, we don't need to be aggressive if a high noise value is
          // updated much less frequently than the other values in the sum.
          double b = scaledX - staticSlacks[j];

          double native[] normalized = Bound.createBound(r, b, currentTime);
          if (!staticWitnesses.containsKey(m) || !((Contract) staticWitnesses.get(m)).implies(m, normalized[0], normalized[1])) {
            staticWitnesses.put(m, m.getThresholdContract(r, b, currentTime));
          }
          // Update the timeout estimate.
          staticTimeout = Math.min(staticTimeout, DirectPolicy.hedgedEstimate(m, normalized[0], normalized[1], currentTime, useWeakCache));
        }

        // Size should be the same for either option.
        Contract native[] finalWitnesses = new Contract native[staticWitnesses.size()];

        if (hasSlackProducer) {
          // If there's a slack producer, see if the dynamic strategy is better.
          double native [] adaptiveSlacks = SumStrategy.getSplitEqualVelocity(velocities, noises, adaptiveRates, (totalValue - baseNow));

          java.util.Map/*<Metric, Contract>*/ adaptiveWitnesses = new java.util.HashMap/*<>*/();
          long adaptiveTimeout = Long.MAX_VALUE;
          for (int j = 0; j < numTerms; j++) {
            Metric m = term(j);
            double scaledX = m.value(useWeakCache);

            //// Adaptive version
            // Corrected for the way this metric is shifting relative to
            // the rest of the sum
            double r = adaptiveRates[j];

            // TODO: Change to account for update frequency in addition to
            // noise, we don't need to be aggressive if a high noise value is
            // updated much less frequently than the other values in the sum.
            double b = scaledX - adaptiveSlacks[j];

            double native[] normalized = Bound.createBound(r, b, currentTime);
            if (!adaptiveWitnesses.containsKey(m) || !((Contract) adaptiveWitnesses.get(m)).implies(m, normalized[0], normalized[1])) {
              adaptiveWitnesses.put(m, m.getThresholdContract(r, b, currentTime));
            }
            // Update the timeout estimate.
            adaptiveTimeout = Math.min(adaptiveTimeout, DirectPolicy.hedgedEstimate(m, normalized[0], normalized[1], currentTime, useWeakCache));
          }

          if (adaptiveTimeout > staticTimeout && adaptiveTimeout - System.currentTimeMillis() > MIN_ADAPTIVE_EXPIRY) {
            int i = 0;
            for (java.util.Iterator iter = adaptiveWitnesses.values().iterator(); iter.hasNext();) {
              finalWitnesses[i++] = (Contract) iter.next();
            }
          } else {
            int i = 0;
            for (java.util.Iterator iter = staticWitnesses.values().iterator(); iter.hasNext();) {
              finalWitnesses[i++] = (Contract) iter.next();
            }
          }
        } else {
          // Otherwise, just go with the static solution.
          int i = 0;
          for (java.util.Iterator iter = staticWitnesses.values().iterator(); iter.hasNext();) {
            finalWitnesses[i++] = (Contract) iter.next();
          }
        }

        return new WitnessPolicy@s().fabric$metrics$contracts$enforcement$WitnessPolicy$(finalWitnesses);
      }
    }

    /*@Override*/
    public int hashCode() {
        return Arrays.hashCode(terms.array()) * 32 + getStore().hashCode();
    }

    /*@Override*/
    public boolean equals(Object other) {
        if (other instanceof SumMetric) {
            SumMetric that = (SumMetric) other;
            return Arrays.deepEquals(this.terms.array(), that.terms.array())
                    && this.$getStore().equals(that.$getStore());
        }
        return false;
    }
}
